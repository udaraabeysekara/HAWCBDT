{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import make_gaussian_quantiles\n",
    "from datetime import datetime\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn import datasets, svm, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 180, 180)\n"
     ]
    }
   ],
   "source": [
    "n_events = 300   # Each event actually produces one gamma ray shower and one cosmic ray shower as per the for loop below,\n",
    "n_pmt = 25     # meaning the total number of events will be twice the input value n_events\n",
    "\n",
    "targets = np.arange(0, 2, 1)\n",
    "increment_targets = np.arange(0, 2, 1)\n",
    "all_images = np.zeros((n_events * 2, 180, 180))\n",
    "print(all_images.shape)\n",
    "\n",
    "for i in range(n_events):\n",
    "    gamma, ray_1 = make_gaussian_quantiles(mean = (8,8), cov = 1,\n",
    "                                             n_samples = n_pmt, n_features = 2,\n",
    "                                             n_classes = 1, random_state = i) \n",
    "\n",
    "    cosmic, ray_2 = make_gaussian_quantiles(mean = (7, 7), cov = 1,\n",
    "                                             n_samples = n_pmt, n_features = 2,\n",
    "                                             n_classes = 1, random_state = i + 2) \n",
    "\n",
    "    # This is slightly confusing, make_gaussian_quantiles defines the variable x as an n x 2 matrix of x, y coordinates\n",
    "    # Now, I'm simply separating that matrix into two arrays: one array of x coordinates, one array of y coordinates\n",
    "\n",
    "    gammax_array = gamma[:, 0]\n",
    "    gammay_array = gamma[:, 1]\n",
    "\n",
    "    cosmicx_array = cosmic[:, 0]\n",
    "    cosmicy_array = cosmic[:, 1]\n",
    "\n",
    "    detection = np.arange(0, n_pmt, 1)\n",
    "\n",
    "    # At some point, ask Udara on what grid system HAWC is built.  Hopefully, the origin is not in the center. \n",
    "    # I think I can define it myself... \n",
    "\n",
    "    for j in range(n_pmt):\n",
    "        detection[j] = 1\n",
    "        gammax_array[j] = \"{0:.1f}\".format(gammax_array[j])\n",
    "        gammay_array[j] = \"{0:.1f}\".format(gammay_array[j])\n",
    "        cosmicx_array[j] = \"{0:.1f}\".format(cosmicx_array[j])\n",
    "        cosmicy_array[j] = \"{0:.1f}\".format(cosmicy_array[j])\n",
    "\n",
    "    pixels = np.arange(0, 18, 0.1)\n",
    "    gammax_indeces = gammax_array*10\n",
    "    gammay_indeces = gammay_array*10\n",
    "    cosmicx_indeces = cosmicx_array*10\n",
    "    cosmicy_indeces = cosmicy_array*10\n",
    "    \n",
    "    all_indeces = [gammax_indeces, gammay_indeces, cosmicx_indeces, cosmicy_indeces]\n",
    "    \n",
    "    for k in range(n_pmt):\n",
    "        for l, idx in zip(range(4), all_indeces):\n",
    "            if idx[k] > 179:\n",
    "                idx[k] = 179.\n",
    "            elif idx[k] < 0.:\n",
    "                idx[k] = 0.\n",
    "        for m, idx2 in zip(range(n_pmt), all_indeces):\n",
    "            if idx2[k] == idx2[m]:\n",
    "                idx2[k] += 1\n",
    "\n",
    "    gammax_min, gammax_max = gammax_indeces.min() - 10, gammax_indeces.max() + 10\n",
    "    gammay_min, gammay_max = gammay_indeces.min() - 10, gammay_indeces.max() + 10\n",
    "    cosmicx_min, cosmicx_max = cosmicx_indeces.min() - 10, cosmicx_indeces.max() + 10\n",
    "    cosmicy_min, cosmicy_max = cosmicy_indeces.min() - 10, cosmicy_indeces.max() + 10\n",
    "    \n",
    "    # Come back to this, these arrays should probably be one and the same for the purpose of training the algorithm\n",
    "    gamma_image = csr_matrix((detection, (gammax_indeces, gammay_indeces)), shape = (len(pixels), len(pixels))).toarray() #These parentheses are important\n",
    "    cosmic_image = csr_matrix((detection, (cosmicx_indeces, cosmicy_indeces)), shape = (len(pixels), len(pixels))).toarray()\n",
    "    \n",
    "    all_images[2 * i] = gamma_image\n",
    "    all_images[(2 * i) + 1] = cosmic_image\n",
    "    \n",
    "    if i == 0: \n",
    "        i = 0\n",
    "    else:\n",
    "        targets = np.concatenate((targets, increment_targets))\n",
    "        \n",
    "images_targets = list(zip(all_images, targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Just to make sure everything seems to be working correctly\n",
    "for n, (image, target) in enumerate(images_targets):\n",
    "    plt.figure(figsize = (8, 8))\n",
    "    plt.imshow(image, cmap = plt.cm.gray, interpolation = 'nearest')\n",
    "    plt.autoscale(enable = True, axis = 'both')\n",
    "    plt.title('Target: %x' %target)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 32400)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape the image to go through classifier\n",
    "data = all_images.reshape((n_events * 2, -1))\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "# Classifier\n",
    "clf = svm.SVC(gamma = 0.001)\n",
    "\n",
    "# Train the algorithm\n",
    "clf.fit(data[:n_events], targets[:n_events])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.99      0.97       150\n",
      "          1       0.99      0.95      0.97       150\n",
      "\n",
      "avg / total       0.97      0.97      0.97       300\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[149   1]\n",
      " [  8 142]]\n"
     ]
    }
   ],
   "source": [
    "expected = targets[:n_events]\n",
    "predicted = clf.predict(data[n_events:])\n",
    "\n",
    "# expected = digits.target[n_samples // 2:]\n",
    "# predicted = classifier.predict(data[n_samples // 2:])\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (clf, metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
